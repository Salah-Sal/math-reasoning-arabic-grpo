model:
  name: "Qwen/Qwen2.5-1.5B-Instruct"
  max_seq_length: 384
  load_in_4bit: true
  fast_inference: false
  gpu_memory_utilization: 0.7
  use_flash_attention: true
  # PEFT configuration
  lora_rank: 16
  lora_alpha: 16
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
    - "gate_proj"
    - "up_proj"
    - "down_proj"
  lora_dropout: 0.05

training:
  learning_rate: 3.0e-6
  max_steps: 1000
  per_device_train_batch_size: 8
  gradient_accumulation_steps: 4
  max_prompt_length: 256
  max_completion_length: 128
  logging_steps: 10
  save_steps: 100
  warmup_steps: 100
  max_checkpoints: 3
  report_to: "none"  # Disable wandb/tensorboard by default

memory:
  gpu_memory_utilization: 0.7
  use_gradient_checkpointing: "unsloth"  # Special value for Unsloth's implementation
  optimize_memory_use: true
  max_memory_MB: 8000
  dtype: "float16"

reward:
  weights:
    xml_structure: 0.3
    format: 0.3
    correctness: 0.4
  cache_size: 1000
  normalize_rewards: true

early_stopping:
  enabled: true
  patience: 5
  min_improvement: 0.01
  min_steps: 100

paths:
  data_path: "/home/Sal3/ml_data/translations"
  output_dir: "outputs/grpo_training"
  checkpoint_dir: "checkpoints"
  log_dir: "logs"
  cache_dir: ".cache" 